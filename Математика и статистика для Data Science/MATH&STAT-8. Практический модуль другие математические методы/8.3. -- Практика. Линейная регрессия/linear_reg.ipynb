{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjUEpVK8MEzG"
   },
   "source": [
    "В Примерах 1 и 2 мы познакомимся с вычислиением скорректированного коэффициента детерминации и его смыслом\n",
    "\n",
    "В Примере 3 увидим, почему нельзя в линейной регрессии доверять экстраполяции\n",
    "\n",
    "В Примере 4 изучим один из способов обнаружить нелинейную зависимость между фактором и целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zbjNmZWMEzO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# импорт библиотек и датасета\n",
    "%pylab inline\n",
    "#%pip install --force-reinstall \"scikit-learn==1.0.2\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0ILq1DuMEze"
   },
   "source": [
    "Пример 1\n",
    "\n",
    "Вычислим обычный и скорректированный коэффициенты детерминации для разных моделей линейных регрессий на примере Boston Housing и посмотрим, как они будут различаться на обучающей и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --force-reinstall \"scikit-learn==1.0.2\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvnosxacMEzh"
   },
   "outputs": [],
   "source": [
    "# загрузим датасет Boston Housing\n",
    "\n",
    "\n",
    "#dataset уданенный\n",
    "#boston = datasets.load_boston()\n",
    "#bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "\n",
    "#dataset новый для работы кода. \n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "bostonDF = pd.DataFrame(raw_df, columns=raw_df.columns)\n",
    "\n",
    "\n",
    "#y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AG0SQm0aMEzu"
   },
   "outputs": [],
   "source": [
    "# добавим мусорный признак в датасет - случайный целочисленный вектор со значениями от 0 до 10\n",
    "bostonDF['TRASH'] = pd.Series(np.random.randint(0,10,506))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aK36H47OMEz3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# разделим датасет на обучающую и тестовую выборки\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# параметр random_state обещает, что каждый раз, когда мы запустим команду, результат деления на train и test будет одинаковым\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# вы можете проверить это, запустив блок несколько раз\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# зададим размер тренировочной выборки 90%\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(bostonDF, \u001b[43my\u001b[49m, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m151\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# любуемся на кусочек результата\u001b[39;00m\n\u001b[0;32m      7\u001b[0m X_train\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# разделим датасет на обучающую и тестовую выборки\n",
    "# параметр random_state обещает, что каждый раз, когда мы запустим команду, результат деления на train и test будет одинаковым\n",
    "# вы можете проверить это, запустив блок несколько раз\n",
    "# зададим размер тренировочной выборки 90%\n",
    "X_train, X_test, y_train, y_test = train_test_split(bostonDF, y, train_size=0.9, random_state=151)\n",
    "# любуемся на кусочек результата\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fn57mt4AME0C"
   },
   "source": [
    "Создадим функцию regscores, которая будет вычислять обычные и исправленные коэффициенты детермианции для тренировочной и тестовой выборок\n",
    "\n",
    "Ее параметры:\n",
    "\n",
    "factors - список столбцов датасета, по которым мы будем прогонять регрессию\n",
    "\n",
    "X_train, X_test, y_train, y_test - тренировочные и тестовые части датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6f77i-GVME0E"
   },
   "outputs": [],
   "source": [
    "def regscores(factors, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # данные, на которых будет обучаться и тестироваться модель\n",
    "    Data_train = X_train[factors]\n",
    "    Data_test = X_test[factors]\n",
    "    \n",
    "    k = len(factors) # количество признаков (без константы)\n",
    "    N_train = Data_train.shape[0] # размер обучающей выборки\n",
    "    N_test = Data_test.shape[0] # размер тестовой вбыорки\n",
    "    \n",
    "    # обучим регрессию и интерсептом на тренировочной выборке\n",
    "    # параметр fit_intercept =True можно не указывать, он установлен по умолчанию\n",
    "    reg = LinearRegression(fit_intercept =True).fit(Data_train, y_train)\n",
    "\n",
    "    # сделаем пердсказания на обучающей и тестовой выборках\n",
    "    y_train_pred = reg.predict(Data_train)\n",
    "    y_test_pred = reg.predict(Data_test)\n",
    "    \n",
    "    # создадим выходной вектор, в который будем записывать результат\n",
    "    r2 = np.zeros(4)\n",
    "    \n",
    "    # R-squared для тренировочной выборки\n",
    "    # (можно использовать reg.score, не импортируя отдельно r2_score)\n",
    "    r2[0] = r2_score(y_train,y_train_pred)\n",
    "    # R-squared adjusted для тренировочной выборки\n",
    "    r2[1] = 1 - (1 - r2[0])*(N_train-1)/(N_train-k)\n",
    "    \n",
    "    # R-squared для тестовой выборки\n",
    "    r2[2] = r2_score(y_test,y_test_pred)\n",
    "    # R-squared adjusted для тестовой выборки\n",
    "    r2[3] = 1 - (1 - r2[2])*(N_test-1)/(N_test-k)\n",
    "    \n",
    "\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyogYw7CME0N"
   },
   "outputs": [],
   "source": [
    "print('Модель с 2 факторами')\n",
    "list_col=['CRIM', 'RM']\n",
    "R2 = regscores(list_col, X_train, X_test, y_train, y_test)\n",
    "print('R-squared для тренировочной выборки = ', R2[0])\n",
    "print('R-squared adj для тренировочной выборки = ', R2[1])\n",
    "print('R-squared для тестовой выборки = ', R2[2])\n",
    "print('R-squared adj для тестовой выборки = ', R2[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWevjru9ME0W"
   },
   "source": [
    "Выводы:\n",
    "\n",
    "1. Коэффициенты детерминации на тренировочной и тестовой выборке примерно одинаковые, а это значит, что модель не переобучилась\n",
    "2. R-sq > R-sq adj\n",
    "3. На тренировочной выборке разница между  R-sq и R-sq adj невелика. Так происходит, потому что размер выборки большой (около 450 точек), а факторов всего 2 - отношение (N-1)/(n-k) будет мало отличаться от 1, а значит и значения коэффициентов детерминации будут близки\n",
    "4. Подумайте, почему на тестовой выборке R-sq и R-sq adj отличаются более заметно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_IBUTw2ME0c"
   },
   "outputs": [],
   "source": [
    "print('Модель с 2 факторами и мусорным фактором')\n",
    "list_col=['CRIM', 'RM','TRASH']\n",
    "R2 = regscores(list_col, X_train, X_test, y_train, y_test)\n",
    "print('R-squared для тренировочной выборки = ', R2[0])\n",
    "print('R-squared adj для тренировочной выборки = ', R2[1])\n",
    "print('R-squared для тестовой выборки = ', R2[2])\n",
    "print('R-squared adj для тестовой выборки = ', R2[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T-hHF7tME0k"
   },
   "source": [
    "Выводы:\n",
    "\n",
    "1. Коэффициенты детерминации на тренировочной и тестовой выборке примерно одинаковые, и это значит, что модель не переобучилась\n",
    "2. R-sq < R-sq adj\n",
    "3. R-sq на обеих выборках чуть выше, чем в модели без мусорного фактора\n",
    "4. R-sq adj на тренировочной выборке отличаются совсем немного. Подумайте, почему?\n",
    "5. R-sq adj на тестовой выборке заметно меньше, чем на тренировочной. Это значит, что R-sq adj \"поймал\" нас на добавлении \"лишнего\" фактора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8aZxxReME0n"
   },
   "outputs": [],
   "source": [
    "list_col=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD','TAX', \n",
    "       'PTRATIO', 'B', 'LSTAT']\n",
    "R2  = regscores(list_col, X_train, X_test, y_train, y_test)\n",
    "print('R-squared для тренировочной выборки = ', R2[0])\n",
    "print('R-squared adj для тренировочной выборки = ', R2[1])\n",
    "print('R-squared для тестовой выборки = ', R2[2])\n",
    "print('R-squared adj для тестовой выборки = ', R2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xfieHpnAME0y"
   },
   "outputs": [],
   "source": [
    "list_col=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
    "       'PTRATIO', 'B', 'LSTAT','TRASH']\n",
    "R2 = regscores(list_col, X_train, X_test, y_train, y_test)\n",
    "print('R-squared для тренировочной выборки = ', R2[0])\n",
    "print('R-squared adj для тренировочной выборки = ', R2[1])\n",
    "print('R-squared для тестовой выборки = ', R2[2])\n",
    "print('R-squared adj для тестовой выборки = ', R2[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "vCNZxTueME08"
   },
   "source": [
    "Выводы для моделей с большим количеством факторов:\n",
    "\n",
    "1. Взяли в модель все имеющиеся факторы. R-sq на train и test отличаются незначительно, а R-sq adj - существенно, около 8%. Дело в том, что данных в тестовой выборке немного, около 50, а факторов много - 13 (или 14). Из-за этого R-sq adj существенно отличается от R-sq на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "PhoHptFOME0_"
   },
   "source": [
    "Общие выводы:\n",
    "\n",
    "1. Если данных немного, то R-sq adj - более точная метрика качества прогнозирующей способности регрессии, так как она учтет количество факторов\n",
    "2. Если данных много (существенно больше, чем факторов), нет большой разницы, что использовать - R-sq или R-sq adj, они будут почти одинаковыми\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yiVEW7vJME1B"
   },
   "source": [
    "Важное замечание:\n",
    "\n",
    "Все классные свойства коэффициентов детерминации работают только для моделей с intercept! В модели без intersept R-sq перестает показывать долю объясненной дисперсии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vE4z3-w8ME1D"
   },
   "source": [
    "Пример 2\n",
    "\n",
    "Посмотрим, как визуально выглядят регрессии с большим и маленьким R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oe0i4FwYME1F",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Очень высокий коэффициент детерминации:')\n",
    "# зададим случайным образом вектор признака а\n",
    "a = np.random.randint(1,100, 50)\n",
    "\n",
    "# зададим линейную зависимость между y и а\n",
    "y=5+10*a+np.random.normal(0,7,len(a))\n",
    "\n",
    "# преобразуем а для LinearRegression\n",
    "adf=pd.DataFrame(a)\n",
    "\n",
    "# прогоним регрессию\n",
    "reg = LinearRegression(fit_intercept =True).fit(adf, y)\n",
    "\n",
    "# найдем коэффициент детерминации\n",
    "print('R-squared = ',reg.score(adf,y))\n",
    "\n",
    "# нарисуем картинку: линия означает регрессионную прямую, точки - настоящие данные\n",
    "y_pred=reg.predict(adf)\n",
    "plt.scatter(a, y,  color='red')\n",
    "plt.plot(a, y_pred, color='blue', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umwI8WuXME1L"
   },
   "outputs": [],
   "source": [
    "print('Менее высокий коэффициент детерминации:')\n",
    "#  добавим еще одну переменную\n",
    "b = np.random.randint(-40,40, 50)\n",
    "\n",
    "# усложним зависимость y от  а, b\n",
    "y=5+10*a+5*b+np.random.normal(0,7,len(a))\n",
    "\n",
    "# прогоним регрессию и выведем результаты\n",
    "adf=pd.DataFrame(a)\n",
    "reg = LinearRegression(fit_intercept =True).fit(adf, y)\n",
    "print('R-squared = ',reg.score(adf,y))\n",
    "y_pred=reg.predict(adf)\n",
    "plt.scatter(a, y,  color='red')\n",
    "plt.plot(a, y_pred, color='blue', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07ZcPi14ME1V"
   },
   "source": [
    "Вывод:\n",
    "\n",
    "1. Чем больше коэффициент детерминации, тем более кучно расположены точки вокруг регрессионной прямой, и, следовательно, тем выше качество предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYob8xQSME1X"
   },
   "source": [
    "Пример 3\n",
    "\n",
    "Интерполяция и экстраполяция  \n",
    "Идея состоит в том, что в моделях простой линейной регрессии (не во временных рядах) мы можем хорошо прогнозировать ТОЛЬКО ВНУТРИ интервалов разброса признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GtJvHP2ME1Z"
   },
   "outputs": [],
   "source": [
    "# создадим массив чисел от -0.4 до 2 с равным шагом 0.02\n",
    "a = np.arange(-20,101)/50\n",
    "# зададим теоретическую зависимость y(a) =  синус + случайная нормальная ошибка с нулевым средним и ст. отклонением 0.1\n",
    "y = np.sin(a) + np.random.normal(0,0.1,len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kQmsN8BME1f"
   },
   "outputs": [],
   "source": [
    "# разделим данные на две группы: группа inter - значения a от -0.2 до 0.8, группа extra - все остальные значения\n",
    "a_inter = pd.DataFrame(a[0:60])\n",
    "y_inter = y[0:60]\n",
    "a_extra = pd.DataFrame(a[61:len(a)-1])\n",
    "y_extra = y[61:len(a)-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3Pzx5UjME1n"
   },
   "outputs": [],
   "source": [
    "# обучим регрессию на группе inter\n",
    "reg = LinearRegression(fit_intercept =True).fit(a_inter, y_inter)\n",
    "print('R-squared = ',reg.score(a_inter, y_inter))\n",
    "y_pred=reg.predict(a_inter)\n",
    "# нарисуем картинку\n",
    "plt.scatter(a_inter, y_inter,  color='green')\n",
    "plt.plot(a_inter, y_pred, color='black', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaIuwmeFME1s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# попробуем сделать предсказания на группе extra\n",
    "y_pred_ex=reg.predict(a_extra)\n",
    "plt.scatter(a_extra, y_extra,  color='green') # точки\n",
    "plt.plot(a_extra, y_pred_ex, color='black', linewidth=1) # ожидание (предсказания модели)\n",
    "plt.plot(a_extra, sin(a_extra), color='blue', linewidth=1) # реальность (настоящие данные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNFpYzYJME1z"
   },
   "source": [
    "На группе inter мы получили идеальную прямую с высоким R-sq. Как только попробовали сделать экстраполяцию - предсказания за пределами отрезка [-0.2, 0.8], модель резко перестала работать.\n",
    "\n",
    "Почему так получилось?\n",
    "\n",
    "Дело в том, что мы уверены в точности прогноза (благодяра высокому R-sq) ТОЛЬКО ВНУТРИ отрезка, на котором обучали регрессию - [-0.2,0.8] Что произойдет с теоретической зависимостью ЗА пределами этого отрезка, мы, находясь в нем, не знаем! В нашем случае на отрезке [-0.2, 0.8] синус ведет себя практически как линейная функция, что и дает нам красивую регрессию. Однако дальше он проявляет во всей красе свою нелинейность и модель больше не валидна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zef1QCQmME11"
   },
   "source": [
    "Пример 4\n",
    "\n",
    "Как можно понять, что линейная модель не подходит к данным?\n",
    "\n",
    "1. Построить scatter plot (y,factor) - по нему можно предположить тренд (линейный, квадратичный, экспоненциальный итп)\n",
    "2. Построить scatter plot остатков регрессионной модели - в нем не должно быть явных паттернов, тогда линейная модель годится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDQi2IeXME13"
   },
   "outputs": [],
   "source": [
    "# создадим массив чисел от -0.2 до 2 с равным шагом 0.02\n",
    "a = np.arange(-20,80)/50\n",
    "# зададим теоретическую зависимость y(a) =  синус + случайная нормальная ошибка с нулевым средним и ст. отклонением 0.1\n",
    "y = np.sin(a) + np.random.normal(0,0.1,len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_TDmRELRME1-"
   },
   "outputs": [],
   "source": [
    "# способ 1\n",
    "# по графику не очень ясно видно, есть нелинейность или нет \n",
    "plt.scatter(a, y,  color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YO7DpCpnME2F"
   },
   "outputs": [],
   "source": [
    "# Способ 2\n",
    "# обучим все регрессию и посмотрим на картинку остатков\n",
    "adf=pd.DataFrame(a)\n",
    "reg = LinearRegression(fit_intercept =True).fit(adf, y)\n",
    "print('R-squared = ',reg.score(adf, y))\n",
    "y_pred = reg.predict(adf)\n",
    "residuals = y - y_pred\n",
    "# нарисуем картинку\n",
    "zero = np.zeros(len(a))\n",
    "plt.scatter(adf, residuals,  color='red')\n",
    "plt.plot(adf,zero, color='green', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTlzdIhlME2K"
   },
   "source": [
    "Мы видим, что в левой и правой части графика остатков почти все точки расположены ниже нулевой отметки, а в середине - выше.\n",
    "\n",
    "Это и есть закономерность - нелинейный паттерн. Линейная модель неприменима"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXQdaBSaME2M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuZ_3orxME2U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "linear_reg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
