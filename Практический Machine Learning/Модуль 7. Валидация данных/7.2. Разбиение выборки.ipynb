{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Какие бывают выборки:\n",
    "\n",
    "1. Обучающая — подмножество данных, на котором мы обучаем модель.\n",
    "2. Валидационная — подмножество данных, на котором мы валидируем модель, то есть проверяем промежуточные результаты. Выборка нужна для проверки модели.\n",
    "3. Тестовая — подмножество данных, на котором мы тестируем модель после проверки всевозможных гипотез."
   ],
   "id": "38294a4d5c175847"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "410c49033e00027b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Как разбить выборку",
   "id": "ed2183354bd9c574"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "сomplete CV — полный скользящий контроль\n",
    "В данном случае оценка строится по всем возможным разбиениям. Важно упомянуть этот метод, однако стоит понимать, что даже при малых размерах длины обучающей выборки число выборки очень большое, и это затрудняет практическое применение данного метода. Полный скользящий контроль используют в теоретических исследованиях или в тех случаях (довольно редких), когда удается вывести вычислительную формулу, позволяющую реализовать вычисления.\n",
    "\n",
    "К примеру, для метода k ближайших соседней такая формула известна, об этом можно почитать тут. Но все же этот метод разбиения используется на практике крайне редко."
   ],
   "id": "50ee23ecef8cae9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "hold-out — отложенная выборка\n",
    "Разбиваем выборку на обучающую, валидационную и, по желанию, на тестовую выборки. Обычно в соотношении 60/40 или 70/30, вместе с тестовой — 60/20/20 или 70/15/15.\n",
    "\n",
    "Данный метод чаще всего применяется в случае больших датасетов в силу того, что требует значительно меньше вычислительных мощностей, чем другие методы.\n",
    "\n",
    "Однако важно помнить, что оценка в этом методе сильно зависит от разбиения. Это плохо, так как оценка должна в первую очередь характеризовать сам алгоритм обучения, а не способ разбиения."
   ],
   "id": "a74b76267d7b05fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "k-fold — cross-validation, перекрёстная валидация\n",
    "1. Разбиваем выборку на k частей.\n",
    "2. Повторяем k раз: обучаем на k-1 частях, валидируем на оставшейся части.\n",
    "3. На каждой итерации валидируем на части данных, на которой ещё не валидировали.\n",
    "4. Усредняем значения метрики.\n",
    "\n",
    "Позволяет сделать оценку качества более робастной — устойчивой к помехам.\n",
    "Чаще всего k имеет значение 10 (или 5 в случае маленьких выборок)."
   ],
   "id": "ceefe1037e6ac927"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "t×k-fold кросс-валидация\n",
    "\n",
    "Процедура выполняется t раз. Обучающая выборка случайным образом разбивается на k непересекающихся, одинаковых по объему частей. Производится k итераций. На каждой итерации происходит k-fold-разбиение.\n",
    "\n",
    "По сути, такой тип валидации — это k-fold валидация, которая повторяется t раз. Такой способ контроля обладает всеми преимуществами k-fold-валидации, но при этом добавляется возможность увеличивать число разбиений."
   ],
   "id": "7042b4e30bb057dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "leave-one-out — отложенный пример\n",
    "Предельный случай k-fold, при котором k равняется размеру всей выборки:\n",
    "\n",
    "1. Выбираем пример для валидации, обучаем на всех остальных.\n",
    "2. Выбираем пример для валидации, который ещё не видели, возвращаемся в пункт 1.\n",
    "\n",
    "Частный случай leave-P-out, при котором нужно перебрать все способы выбора P-элементов из выборки.  Большим недостатком данного метода является то, что он очень ресурсозатратен. Однако нельзя утверждать, что он вообще не используется. В некоторых методах обучения вычисление LOO получается заметно ускорить, и его использование становится возможным."
   ],
   "id": "2e155b22fb571f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Проблемы при разбиении\n",
    "1. Обучение на тестовой выборке.\n",
    "2. В тренировочной и тестовой выборках оказываются данные разной природы.\n",
    "Пример: при классификации автомобилей в тренировочную выборку попали примеры с одними типами двигателей, а в тестовую — с другими.\n",
    "3. В тренировочной и тестовой выборках оказываются примеры со схожими признаками.\n",
    "Пример: при обучении модели предсказывают пол, разные фотографии одного и того же человека попадают в разные выборки."
   ],
   "id": "5e4f6c13349e5834"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Реализация в Python",
   "id": "3a10253c47d752c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Для разбиения выборки в Python есть специальная функция test_train_split из библиотеки Scikit-learn:",
   "id": "f043349150968250"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:54:38.962912Z",
     "start_time": "2025-04-02T12:54:38.263365Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split",
   "id": "cbf0de7619c3cdf9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "После этого мы должны обозначить нашу зависимую переменную (Y) и независимые (X) и с помощью этой функции создать обучающую и тестовую выборки:",
   "id": "b21a6fcfe288e3b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:55:05.395255Z",
     "start_time": "2025-04-02T12:55:05.344735Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.65,test_size=0.35, random_state=101)",
   "id": "92eb644cc5ed10d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "train_size — аргумент, отвечающий за размер обучающей выборки (доля).\n",
    "\n",
    "random_state является необязательным аргументом. Но дело в том, что разбиение каждый раз будет разным. Если задать явным образом значение random_state, то генерируемые псевдослучайные величины будут иметь одни и те же значения при каждом запуске алгоритма.\n",
    "\n",
    "Для кросс-валидации также есть специальные функции. Например, ниже пример k-fold c двумя разбиениями на двух фолдах:"
   ],
   "id": "ac4748b274d5eda1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:55:26.189501Z",
     "start_time": "2025-04-02T12:55:26.149869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)  #реализация разбиения\n",
    "kf.get_n_splits(X) #возвращает количество разбиений\n",
    "kf.split(X) #возвращает индексы для разбиения"
   ],
   "id": "e1d2fa7b197cb8d1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
