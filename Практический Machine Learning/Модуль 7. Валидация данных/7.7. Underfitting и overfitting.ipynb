{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"xblock xblock-student_view xblock-student_view-html xmodule_display xmodule_HtmlBlock xblock-initialized\" data-course-id=\"course-v1:SkillFactory+MATML+ALWAYS\" data-mark-completed-on-view-after-delay=\"0\" data-init=\"XBlockToXModuleShim\" data-runtime-class=\"LmsRuntime\" data-runtime-version=\"1\" data-block-type=\"html\" data-usage-id=\"block-v1:SkillFactory+MATML+ALWAYS+type@html+block@f3eb1ac794dd4de4b14b3436c849603a\" data-request-token=\"a53e7fb6203311f091bf8a486b5575bd\" data-graded=\"True\" data-has-score=\"False\">\n",
    "\n",
    "  <p style=\"font-size: 16px;\"><span style=\"color: #33b549;\"><strong>Переобучение (overfitting)</strong>&nbsp;</span>— проблема, при которой алгоритм чувствителен к незначительным колебаниям в данных в процессе обучения. Из-за этого алгоритм выучивает обучающий набор данных.</p>\n",
    "<div style=\"background-color: #64cb8c;padding: 20px;margin-top: 20px;margin-bottom: 20px;border-radius: 10px;\">\n",
    "<h2><strong>Как избавиться от переобучения</strong></h2>\n",
    "<ul>\n",
    "<ul>\n",
    "<li>Отложенная выборка (hold-out).</li>\n",
    "<li>k-fold валидация или leave-one-out валидация.</li>\n",
    "<li>Уменьшение сложности модели.</li>\n",
    "<li>Регуляризация.</li>\n",
    "<li>Добавление данных.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "</div>\n",
    "<p style=\"font-size: 16px;\"></p>\n",
    "<p style=\"font-size: 16px;\"><span style=\"color: #33b549;\"><strong>Недообучение (underfitting)</strong>&nbsp;</span>— проблема, при которой алгоритм недостаточно хорошо изучил данные и пропускает важные зависимости между признаками. В случае недообучения мы даже на обучающих данных не можем достичь приемлемых оценок для модели.</p>\n",
    "<p><span style=\"color: #33b549;\"><strong>Почему может возникать недообучение?</strong></span></p>\n",
    "<ul>\n",
    "<li>Неправильно подобранный алгоритм обучения;</li>\n",
    "<li>Неадекватная функция ошибки;</li>\n",
    "<li>Не настроены или неправильно настроены гиперпараметры;</li>\n",
    "<li>Недостаточно данных для обучения. Зачастую, если увеличить обучающую выборку, то модель, которая раньше недообучалась, избавится от этой проблемы.</li>\n",
    "</ul>\n",
    "<div style=\"background-color: #64cb8c;padding: 20px;margin-top: 20px;margin-bottom: 20px;border-radius: 10px;\">\n",
    "<h2><strong>Как избавиться от недообучения?</strong></h2>\n",
    "<ul>\n",
    "<ul>\n",
    "<li>Усложнение модели.</li>\n",
    "<li>Ослабевание параметров регуляризации.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "</div>\n",
    "<p style=\"font-size: 16px;\">Чтобы лучше разобраться и лучше понять смысл переобучения и недообучения, рассмотрим иллюстративно на известных нам методах.</p>\n",
    "<p style=\"font-size: 16px;\"><strong>Начнем с линейной регрессии:</strong></p>\n",
    "<center><img width=\"100%\" src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/e7a7fff0526bbd908daf81a6c1ac513e/asset-v1:SkillFactory+MATML+ALWAYS+type@asset+block/7.8.1.jpg\" style=\"-webkit-filter: drop-shadow(5px 5px 5px #222); filter: drop-shadow(5px 5px 5px #666666); margin-bottom: 20px; border-radius: 10px;\" alt=\"\"></center>\n",
    "<p>На данной картинке <span style=\"color: #ff0000;\">красными</span> крестиками обозначены исходные данные, а <span style=\"color: #3366ff;\">синие</span> линии — аппроксимация исходных данных (предсказание).</p>\n",
    "<p>На левом рисунке мы можем видеть, что простая линейная функция плоха для этих данных: там явно <span style=\"color: #33b549;\"><strong>нелинейная зависимость</strong></span>. Поэтому модель будет не очень качественной.</p>\n",
    "<p>На средней картинке <span style=\"color: #33b549;\"><strong>оптимальный</strong></span> для нас вариант: функция не идеально подгоняется под все данные, но хорошо описывает закономерность.</p>\n",
    "<p>А на правой картинке можно наблюдать слишком сильную подгонку под обучающие данные, что приведет к <span style=\"color: #33b549;\"><strong>низкой прогностической способности</strong></span> на новых данных.</p>\n",
    "<p>Теперь рассмотрим иллюстрацию недообучения и переобучения <strong>в случае классификации:</strong></p>\n",
    "<center><img width=\"100%\" src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/832d24dc0f6274089e2dd4252f9822dc/asset-v1:SkillFactory+MATML+ALWAYS+type@asset+block/7.8.2.jpg\" style=\"-webkit-filter: drop-shadow(5px 5px 5px #222); filter: drop-shadow(5px 5px 5px #666666); margin-bottom: 20px; border-radius: 10px;\" alt=\"\"></center>\n",
    "<p>На левой картинке мы можем видеть <span style=\"color: #33b549;\"><strong>плохую</strong> </span>классификацию. Модель слишком проста и некачественно разделяет&nbsp; объекты по классам.</p>\n",
    "<p>На центральной картинке практически <span style=\"color: #33b549;\"><strong>идеальная</strong> </span>ситуация: выбрана более сложная модель, которая хорошо разделяет классы.</p>\n",
    "<p>А вот на правой картинке — явный пример <span style=\"color: #33b549;\"><strong>переобучения</strong></span>: выбрана очень сложная модель, которая максимально подогнана под обучающие данные, однако на новых данных она скорее всего будет сильно ошибаться.</p>\n",
    "<p></p>\n",
    "\n",
    "<p></p>\n",
    "<p></p>\n",
    "</div>"
   ],
   "id": "b01a734d60247762"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
